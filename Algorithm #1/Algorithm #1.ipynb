{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm #1 Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import cv2\n",
    "from skimage.color import rgb2ycbcr, ycbcr2rgb\n",
    "from skimage.transform import resize\n",
    "from sklearn.preprocessing import normalize\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np \n",
    "from skimage.transform import resize\n",
    "from scipy.signal import convolve2d\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Sign Algorithm for Quadratic Programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureSign(y: np.ndarray, A: np.ndarray, lamb):\n",
    "    EPS = 1e-9 #epsilon for comparisons\n",
    "    \n",
    "    x = np.zeros((A.shape[1], 1)) #initialize x\n",
    "    theta = np.sign(x) #initialize theta\n",
    "    y = y.reshape((-1, 1)) #reshape y to a column vector for ease of calculations\n",
    "    gradient = (2 * (A.T @ A @ x)) - (2 * (A.T @ y))  #initial value of gradient \n",
    "    active_set = np.zeros(shape = x.shape) #initialize active set\n",
    "    \n",
    "    #Iterate\n",
    "    for _ in range(10):\n",
    "        gradient_max_idx = np.argmax(np.abs(gradient) * (x == 0))\n",
    "        Ai = A[:, gradient_max_idx].flatten().reshape((-1, 1))\n",
    "        \n",
    "        if gradient[gradient_max_idx] > lamb + EPS:\n",
    "            x[gradient_max_idx] = (lamb - gradient[gradient_max_idx]) / (2 * (np.linalg.norm(Ai) ** 2))\n",
    "            theta[gradient_max_idx] = -1\n",
    "            active_set[gradient_max_idx] = 1\n",
    "        elif gradient[gradient_max_idx] < -lamb - EPS:\n",
    "            x[gradient_max_idx] = (-lamb - gradient[gradient_max_idx]) / (2 * (np.linalg.norm(Ai) ** 2))\n",
    "            theta[gradient_max_idx] = 1\n",
    "            active_set[gradient_max_idx] = 1\n",
    "        else:\n",
    "            if np.all(x == 0):\n",
    "                break\n",
    "        \n",
    "        #Feature-Sign Step\n",
    "        for _ in range(10):\n",
    "            x_non_zero_idxes = (x != 0).flatten()\n",
    "            A_hat = A[:, x_non_zero_idxes]\n",
    "            x_hat = x[x_non_zero_idxes, :]\n",
    "            theta_hat = theta[x_non_zero_idxes, :]\n",
    "            \n",
    "            x_hat_new = np.linalg.lstsq(A_hat.T @ A_hat, A_hat.T @ y - 0.5 * lamb * theta_hat, rcond=None)[0]            \n",
    "            loss_new = np.linalg.norm(y - A_hat @ x_hat_new) ** 2 + lamb * np.sum(abs(x_hat_new))\n",
    "            \n",
    "            idx_hats = np.where(x_hat * x_hat_new < 0) [0]\n",
    "            if np.all(idx_hats == 0):\n",
    "                x_hat = x_hat_new\n",
    "                \n",
    "                x[x_non_zero_idxes, :] = x_hat\n",
    "                theta = np.sign(x)\n",
    "                active_set = (x != 0)\n",
    "                \n",
    "            else:\n",
    "                x_min = x_hat_new\n",
    "                loss_min = loss_new\n",
    "                diff = x_min - x_hat\n",
    "                delta = diff / x_hat\n",
    "                \n",
    "                for zd in idx_hats.T:\n",
    "                    x_s = x_hat - diff / delta[zd]\n",
    "                    x_s[zd] = 0\n",
    "                    x_s_idx = (x_s == 0).flatten()\n",
    "                    \n",
    "                    A_hat_s_idx = A_hat[:, x_s_idx]\n",
    "                    x_s_modified = x_s[x_s_idx, :]\n",
    "                    \n",
    "                    loss = np.linalg.norm(y - A_hat_s_idx @ x_s_modified) ** 2 + lamb * np.sum(abs(x_s_modified))\n",
    "                    if loss < loss_min:\n",
    "                        x_min = x_s\n",
    "                        loss_min = loss\n",
    "                \n",
    "                x[x_non_zero_idxes, :] = x_min\n",
    "                theta = np.sign(x)\n",
    "                active_set = (x != 0)     \n",
    "            \n",
    "            gradient = (2 * (A.T @ A @ x)) - (2 * (A.T @ y))\n",
    "            non_zero_idxs = (x != 0).flatten()\n",
    "            if np.all(gradient[non_zero_idxs, :] + lamb * theta[non_zero_idxs, :] == 0):\n",
    "                break\n",
    "            \n",
    "        zero_idxs = (x == 0).flatten()\n",
    "        if np.all(gradient[zero_idxs, :] <= lamb):\n",
    "            break\n",
    "                    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Super Resolution Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute Features using First and Second Order Gradient Filters\n",
    "def F(img_lr: np.ndarray):\n",
    "    h, w = img_lr.shape\n",
    "    img_lr_feat = np.zeros((h, w, 4))\n",
    "\n",
    "    # First order gradient filters\n",
    "    hf1 = [[-1, 0, 1], ] * 3\n",
    "    vf1 = np.transpose(hf1)\n",
    "\n",
    "    img_lr_feat[:, :, 0] = convolve2d(img_lr, hf1, 'same')\n",
    "    img_lr_feat[:, :, 1] = convolve2d(img_lr, vf1, 'same')\n",
    "\n",
    "    # Second order gradient filters\n",
    "    hf2 = [[1, 0, -2, 0, 1], ] * 3\n",
    "    vf2 = np.transpose(hf2)\n",
    "\n",
    "    img_lr_feat[:, :, 2] = convolve2d(img_lr, hf2, 'same')\n",
    "    img_lr_feat[:, :, 3] = convolve2d(img_lr, vf2, 'same')\n",
    "\n",
    "    return img_lr_feat\n",
    "\n",
    "def lin_scale(xh, us_norm):\n",
    "    hr_norm = np.linalg.norm(xh)\n",
    "\n",
    "    if hr_norm > 0:\n",
    "        s = us_norm * 1.2 / hr_norm\n",
    "        xh *= s\n",
    "    return xh\n",
    "\n",
    "def SR(img_lr_y, size, upscale, Dh, Dl, lmbd, overlap):\n",
    "    patch_size = 5\n",
    "\n",
    "    #Upsample the low resolution image\n",
    "    img_us = resize(img_lr_y, size)\n",
    "    img_us_height, img_us_width = img_us.shape\n",
    "    \n",
    "    #Initialize the high resolution image\n",
    "    img_hr = np.zeros(img_us.shape)\n",
    "    cnt_matrix = np.zeros(img_us.shape)\n",
    "\n",
    "    #Extract first order and second order gradients from the upscaled, low resolution image\n",
    "    img_lr_y_feat = F(img_us)\n",
    "\n",
    "    #Create a grid over which we can obtain all the patches\n",
    "    gridx = np.append(np.arange(0, img_us_width - patch_size - 1, patch_size - overlap), img_us_width - patch_size - 1)\n",
    "    gridy = np.append(np.arange(0, img_us_height - patch_size - 1, patch_size - overlap), img_us_height - patch_size - 1)\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    #Iterate over each point in the grid\n",
    "    for m in tqdm(range(0, len(gridx))):\n",
    "        for n in range(0, len(gridy)):\n",
    "            count += 1\n",
    "            xx = int(gridx[m])\n",
    "            yy = int(gridy[n])\n",
    "\n",
    "            #Get Upsampled patch from the Low Res Image\n",
    "            us_patch = img_us[yy : yy + patch_size, xx : xx + patch_size]\n",
    "            us_mean = np.mean(us_patch)\n",
    "            us_patch = us_patch.flatten(order='F') - us_mean\n",
    "            us_norm = np.linalg.norm(us_patch)\n",
    "\n",
    "            #Get Feature Patch from Gradient Patch\n",
    "            feat_patch = img_lr_y_feat[yy : yy + patch_size, xx : xx + patch_size, :]\n",
    "            feat_patch = feat_patch.flatten(order='F')\n",
    "            feat_norm = np.linalg.norm(feat_patch)\n",
    "            \n",
    "            #Normalize Feature Patch if needed\n",
    "            if feat_norm > 1:\n",
    "                y = feat_patch / feat_norm\n",
    "            else:\n",
    "                y = feat_patch\n",
    "                \n",
    "            w = featureSign(y, Dl, lmbd)\n",
    "\n",
    "            hr_patch = Dh @ w\n",
    "            hr_patch = lin_scale(hr_patch, us_norm)\n",
    "\n",
    "            hr_patch = np.reshape(hr_patch, (patch_size, -1))\n",
    "            hr_patch += us_mean\n",
    "\n",
    "            img_hr[yy : yy + patch_size, xx : xx + patch_size] += hr_patch\n",
    "            cnt_matrix[yy : yy + patch_size, xx : xx + patch_size] += 1\n",
    "\n",
    "    index = np.where(cnt_matrix < 1)[0]\n",
    "    img_hr[index] = img_us[index]\n",
    "    cnt_matrix[index] = 1\n",
    "    img_hr = np.divide(img_hr, cnt_matrix)\n",
    "    return img_hr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backprojection Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss2D(shape,sigma):\n",
    "    m,n = [(ss-1.)/2. for ss in shape]\n",
    "    y,x = np.ogrid[-m:m+1,-n:n+1]\n",
    "    h = np.exp( -(x*x + y*y) / (2.*sigma*sigma) )\n",
    "    h[ h < np.finfo(h.dtype).eps*h.max() ] = 0\n",
    "    sumh = h.sum()\n",
    "    if sumh != 0:\n",
    "        h /= sumh\n",
    "    return h\n",
    "\n",
    "def backprojection(img_hr, img_lr, maxIter):\n",
    "    p = gauss2D((5, 5), 1)\n",
    "    p = np.multiply(p, p)\n",
    "    p = np.divide(p, np.sum(p))\n",
    "\n",
    "    for i in range(maxIter):\n",
    "        img_lr_ds = resize(img_hr, img_lr.shape, anti_aliasing=1)\n",
    "        img_diff = img_lr - img_lr_ds\n",
    "\n",
    "        img_diff = resize(img_diff, img_hr.shape)\n",
    "        img_hr += convolve2d(img_diff, p, 'same')\n",
    "    return img_hr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 32/128 [08:04<24:14, 15.15s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 44\u001b[0m\n\u001b[1;32m     41\u001b[0m img_sr_cr \u001b[38;5;241m=\u001b[39m resize(img_lr_cr, (img_hr\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], img_hr\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]), order\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Super Resolution via Sparse Representation\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m img_sr_y \u001b[38;5;241m=\u001b[39m SR(img_lr_y, img_hr_y\u001b[38;5;241m.\u001b[39mshape, upscale, Dh, Dl, lmbd, overlap)\n\u001b[1;32m     45\u001b[0m img_sr_y \u001b[38;5;241m=\u001b[39m backprojection(img_sr_y, img_lr_y, maxIter)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Create colored SR images\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 74\u001b[0m, in \u001b[0;36mSR\u001b[0;34m(img_lr_y, size, upscale, Dh, Dl, lmbd, overlap)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     y \u001b[38;5;241m=\u001b[39m feat_patch\n\u001b[0;32m---> 74\u001b[0m w \u001b[38;5;241m=\u001b[39m featureSign(y, Dl, lmbd)\n\u001b[1;32m     76\u001b[0m hr_patch \u001b[38;5;241m=\u001b[39m Dh \u001b[38;5;241m@\u001b[39m w\n\u001b[1;32m     77\u001b[0m hr_patch \u001b[38;5;241m=\u001b[39m lin_scale(hr_patch, us_norm)\n",
      "Cell \u001b[0;32mIn[2], line 69\u001b[0m, in \u001b[0;36mfeatureSign\u001b[0;34m(y, A, lamb)\u001b[0m\n\u001b[1;32m     66\u001b[0m     active_set \u001b[38;5;241m=\u001b[39m (x \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m)     \n\u001b[1;32m     68\u001b[0m gradient \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m (A\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m A \u001b[38;5;241m@\u001b[39m x)) \u001b[38;5;241m-\u001b[39m (\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m (A\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m y))\n\u001b[0;32m---> 69\u001b[0m non_zero_idxs \u001b[38;5;241m=\u001b[39m (x \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(gradient[non_zero_idxs, :] \u001b[38;5;241m+\u001b[39m lamb \u001b[38;5;241m*\u001b[39m theta[non_zero_idxs, :] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Set which dictionary you want to use    \n",
    "Dh = np.load(\"../Dictionaries/Dh.npy\")\n",
    "Dl = np.load(\"../Dictionaries/Dl.npy\")\n",
    "\n",
    "Dh = normalize(Dh)\n",
    "Dl = normalize(Dl)\n",
    "\n",
    "### SET PARAMETERS\n",
    "lmbd = 0.1\n",
    "patch_size= 5\n",
    "D_size = 512\n",
    "US_mag = 3\n",
    "\n",
    "overlap = 1\n",
    "lmbd = 0.1\n",
    "upscale = 4\n",
    "maxIter = 100\n",
    "\n",
    "lr_image_path = \"../Data/Testing/Child.png\"\n",
    "hr_image_path = \"../Data/Testing/Child_gnd.bmp\"\n",
    "\n",
    "#Read Low Resolution Image. Cv2 reads in BGR order so must be flipped! \n",
    "img_lr = cv2.imread(lr_image_path)\n",
    "img_lr_ori = img_lr #store original low resolution image\n",
    "img_lr = cv2.cvtColor(img_lr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Read and save ground truth image[High Resolution Image]\n",
    "img_hr = cv2.imread(hr_image_path)\n",
    "img_hr = cv2.cvtColor(img_hr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Change color space for Low Res and High Res Image\n",
    "img_hr_y = rgb2ycbcr(img_hr)[:, :, 0] #Get Convert RGB to Y, CB, Cr and get Y component for High Resolution Image\n",
    "\n",
    "img_lr = rgb2ycbcr(img_lr) #Get Convert RGB to Y, CB, Cr for Low Resolution Image\n",
    "img_lr_y = img_lr[:, :, 0] #Y Component\n",
    "img_lr_cb = img_lr[:, :, 1] #CB Component\n",
    "img_lr_cr = img_lr[:, :, 2] #Cr Component\n",
    "\n",
    "# Upscale chrominance to color SR images\n",
    "img_sr_cb = resize(img_lr_cb, (img_hr.shape[0], img_hr.shape[1]), order=0)\n",
    "img_sr_cr = resize(img_lr_cr, (img_hr.shape[0], img_hr.shape[1]), order=0)\n",
    "\n",
    "# Super Resolution via Sparse Representation\n",
    "img_sr_y = SR(img_lr_y, img_hr_y.shape, upscale, Dh, Dl, lmbd, overlap)\n",
    "img_sr_y = backprojection(img_sr_y, img_lr_y, maxIter)\n",
    "    \n",
    "# Create colored SR images\n",
    "img_sr = np.stack((img_sr_y, img_sr_cb, img_sr_cr), axis=2)\n",
    "img_sr = ycbcr2rgb(img_sr)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(10, 5))  # Create a figure with 1 row and 2 columns\n",
    "\n",
    "axes[0].imshow(img_sr)  # You can choose different colormaps ('gray' for grayscale)\n",
    "axes[0].set_title('SuperResolution Image')  # Set title\n",
    "axes[0].set_xlabel('Columns')  # Set label for x-axis\n",
    "axes[0].set_ylabel('Rows')  # Set label for y-axis\n",
    "\n",
    "axes[1].imshow(resize(cv2.cvtColor(img_lr_ori, cv2.COLOR_BGR2RGB), (img_hr.shape[0], img_hr.shape[1]), order = 0), cmap='gray')  # You can choose different colormaps ('gray' for grayscale)\n",
    "axes[1].set_title('Original Low Resolution Image')  # Set title\n",
    "axes[1].set_xlabel('Columns')  # Set label for x-axis\n",
    "axes[1].set_ylabel('Rows')  # Set label for y-axis\n",
    "\n",
    "\n",
    "axes[2].imshow(img_hr, cmap='gray')  # You can choose different colormaps ('gray' for grayscale)\n",
    "axes[2].set_title('Ground Truth High Res Resolution Image')  # Set title\n",
    "axes[2].set_xlabel('Columns')  # Set label for x-axis\n",
    "axes[2].set_ylabel('Rows')  # Set label for y-axis\n",
    "\n",
    "plt.tight_layout()  # Adjust layout to prevent overlap\n",
    "plt.show()  # Display the figure with subplots"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuroimaging",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
